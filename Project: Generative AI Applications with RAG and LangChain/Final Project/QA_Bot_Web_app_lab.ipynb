{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df3bd26-5a22-4590-8d0c-88087ab1c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ibm-watsonx-ai==1.1.2\n",
    "!pip install langchain-ibm==0.1.11\n",
    "!pip install langchain-community==0.2.10\n",
    "!pip install langchain==0.2.11\n",
    "!pip install gradio==4.44.0\n",
    "!pip install pypdf==4.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ddc68539-ffe8-4a3b-a3ac-a38003a9d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from langchain_ibm import WatsonxLLM, WatsonxEmbeddings\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7b0f7-1e5e-4c6e-a4f4-9fcc354baa08",
   "metadata": {},
   "source": [
    "# Task 1: Load document using LangChain for different sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75efab30-6ecb-44a9-b435-dcdcf16ca35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_loader(file):\n",
    "    loader = PyPDFLoader(file)\n",
    "    pages = loader.load_and_split()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fe80c20-dc9e-4593-b1dd-2bf205620b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Comprehensive Review of Low-Rank\\nAdaptation in Large Language Models for\\nEfficient Parameter Tuning\\nSeptember 10, 2024\\nAbstract\\nNatural Language Processing (NLP) often involves pre-training large\\nmodels on extensive datasets and then adapting them for specific tasks\\nthrough fine-tuning. However, as these models grow larger, like GPT-3\\nwith 175 billion parameters, fully fine-tuning them becomes computa-\\ntionally expensive. We propose a novel method called LoRA (Low-Rank\\nAdaptation) that significantly reduces the overhead by freezing the orig-\\ninal model weights and only training small rank decomposition matrices.\\nThis leads to up to 10,000 times fewer trainable parameters and reduces\\nGPU memory usage by three times. LoRA not only maintains but some-\\ntimes surpasses fine-tuning performance on models like RoBERTa, De-\\nBERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\\nno extra latency during inference, making it more efficient for practical\\napplications. All relevant code an'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WgM1DaUn2SYPcCg_It57tA/A-Comprehensive-Review-of-Low-Rank-Adaptation-in-Large-Language-Models-for-Efficient-Parameter-Tuning-1.pdf'\n",
    "data = document_loader(pdf_url)\n",
    "text = \" \".join([page.page_content for page in data])\n",
    "first_1000_char = text[:1000]\n",
    "first_1000_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b5b18-be9c-429a-ba73-26840f0ef7ff",
   "metadata": {},
   "source": [
    "# Task 2: Apply text splitting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8776aed4-eb8d-49ee-8dcd-e70ab3bc9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language=Language.LATEX,\n",
    "        chunk_size=60,\n",
    "        chunk_overlap=5,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_text(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b906f01-db20-4f05-9c92-3ea9a586987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\documentclass{article}\\n\\n    \\x08egin{document}',\n",
       " '\\\\maketitle\\n\\n    \\\\section{Introduction}\\n\\n    Large',\n",
       " 'language models (LLMs) are a type of machine learning model',\n",
       " 'that can be trained on vast amounts of text data to',\n",
       " 'to generate human-like language. In recent years, LLMs have',\n",
       " 'have made significant advances in various natural language',\n",
       " 'processing tasks, including language translation, text',\n",
       " 'text generation, and sentiment analysis.',\n",
       " '\\\\subsection{History of LLMs}\\n\\nThe earliest LLMs were',\n",
       " 'were developed in the 1980s and 1990s, but they were',\n",
       " 'were limited by the amount of data that could be processed',\n",
       " 'and the computational power available at the time. In the',\n",
       " 'the past decade, however, advances in hardware and software',\n",
       " 'have made it possible to train LLMs on massive datasets,',\n",
       " 'leading to significant improvements in performance.',\n",
       " '\\\\subsection{Applications of LLMs}\\n\\nLLMs have many',\n",
       " 'many applications in the industry, including chatbots,',\n",
       " 'content creation, and virtual assistants. They can also be',\n",
       " 'be used in academia for research in linguistics,',\n",
       " 'psychology, and computational linguistics.\\n\\n\\\\end{document}']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_text = \"\"\"\n",
    "\n",
    "    \\documentclass{article}\n",
    "\n",
    "    \\begin{document}\n",
    "\n",
    "    \\maketitle\n",
    "\n",
    "    \\section{Introduction}\n",
    "\n",
    "    Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "\n",
    "    \\subsection{History of LLMs}\n",
    "\n",
    "The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "\n",
    "\\subsection{Applications of LLMs}\n",
    "\n",
    "LLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chunks = text_splitter(latex_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c1b67-ba66-405e-93c9-ccbbb98e76ae",
   "metadata": {},
   "source": [
    "# Task 3: Embed documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c33cc6b-7a15-41a2-8c56-b4ccfdb869ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_token = \"your_iam_token_here\"  # Replace with the IAM token you just obtained\n",
    "\n",
    "def watsonx_embedding():\n",
    "    embed_params = {\n",
    "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "    }\n",
    "\n",
    "    # Initialize WatsonxEmbeddings with IAM token\n",
    "    watsonx_embedding = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",  \n",
    "        project_id=\"skills-network\",  \n",
    "        params=embed_params,\n",
    "    )\n",
    "\n",
    "    return watsonx_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "233f1c16-4e6a-4c8c-aa6c-4570503e14ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting IAM Token.\n",
      "Reason: <Response [400]>\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Error getting IAM Token.\nReason: <Response [400]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m embed \u001b[38;5;241m=\u001b[39m watsonx_embedding()\n\u001b[0;32m      4\u001b[0m embedding_vec \u001b[38;5;241m=\u001b[39m embed\u001b[38;5;241m.\u001b[39membed_documents([query])\n\u001b[0;32m      5\u001b[0m embedding_vec[:\u001b[38;5;241m5\u001b[39m]\n",
      "Cell \u001b[1;32mIn[57], line 10\u001b[0m, in \u001b[0;36mwatsonx_embedding\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m embed_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     EmbedTextParamsMetaNames\u001b[38;5;241m.\u001b[39mTRUNCATE_INPUT_TOKENS: \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      6\u001b[0m     EmbedTextParamsMetaNames\u001b[38;5;241m.\u001b[39mRETURN_OPTIONS: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize WatsonxEmbeddings with IAM token\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m watsonx_embedding \u001b[38;5;241m=\u001b[39m WatsonxEmbeddings(\n\u001b[0;32m     11\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibm/slate-125m-english-rtrvr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://us-south.ml.cloud.ibm.com\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Ensure this is the correct region\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     project_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskills-network\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Your project ID\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     apikey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Don't use API key here\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     iam_token\u001b[38;5;241m=\u001b[39miam_token,  \u001b[38;5;66;03m# Use the IAM token instead\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     params\u001b[38;5;241m=\u001b[39membed_params,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m watsonx_embedding\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m validator(cls_, values)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_ibm\\embeddings.py:155\u001b[0m, in \u001b[0;36mWatsonxEmbeddings.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    128\u001b[0m             values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m convert_to_secret_str(\n\u001b[0;32m    129\u001b[0m                 get_from_dict_or_env(\n\u001b[0;32m    130\u001b[0m                     values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWATSONX_INSTANCE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m                 )\n\u001b[0;32m    132\u001b[0m             )\n\u001b[0;32m    134\u001b[0m     credentials \u001b[38;5;241m=\u001b[39m Credentials(\n\u001b[0;32m    135\u001b[0m         url\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value() \u001b[38;5;28;01mif\u001b[39;00m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    136\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapikey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         verify\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     watsonx_embed \u001b[38;5;241m=\u001b[39m Embeddings(\n\u001b[0;32m    156\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    157\u001b[0m         params\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    158\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    159\u001b[0m         project_id\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    160\u001b[0m         space_id\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwatsonx_embed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m watsonx_embed\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models\\embeddings\\embeddings.py:139\u001b[0m, in \u001b[0;36mEmbeddings.__init__\u001b[1;34m(self, model_id, params, credentials, project_id, space_id, api_client, verify, persistent_connection)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m credentials:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watsonx_ai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APIClient\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m APIClient(credentials, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_client:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m api_client\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\client.py:365\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[1;34m(self, credentials, project_id, space_id, verify, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# For cloud, service_instance.details will be set during space creation( if instance is associated ) or\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# while patching a space with an instance\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_instance: ServiceInstance \u001b[38;5;241m=\u001b[39m ServiceInstance(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolumes \u001b[38;5;241m=\u001b[39m Volume(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_fm_ga_api:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\service_instance.py:56\u001b[0m, in \u001b[0;36mServiceInstance.__init__\u001b[1;34m(self, client)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# This is used in connections.py\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_href_definitions \u001b[38;5;241m=\u001b[39m HrefDefinitions(\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mPLATFORM_URL,\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES,\n\u001b[0;32m     54\u001b[0m )\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_token()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mproceed:  \u001b[38;5;66;03m# there is no 'token' in credentials\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_expiration_datetime() \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\service_instance.py:237\u001b[0m, in \u001b[0;36mServiceInstance._get_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_token\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_token()\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_token_refresh_possible():\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\service_instance.py:273\u001b[0m, in \u001b[0;36mServiceInstance._create_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_is_IAM():\n\u001b[1;32m--> 273\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_IAM_token()\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[0;32m    276\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key for IAM token is not provided in credentials for the client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\service_instance.py:345\u001b[0m, in \u001b[0;36mServiceInstance._get_IAM_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expiration_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError getting IAM Token.\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "\u001b[1;31mWMLClientError\u001b[0m: Error getting IAM Token.\nReason: <Response [400]>"
     ]
    }
   ],
   "source": [
    "query = \"How are you?\"\n",
    "embed = watsonx_embedding()\n",
    "\n",
    "embedding_vec = embed.embed_documents([query])\n",
    "embedding_vec[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352b4a8-3d4a-4563-a03d-de48c648d9a7",
   "metadata": {},
   "source": [
    "# Task 4: Create and configure vector databases to store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587fb1b1-056e-4a5e-b71a-d51b52b4b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_database(chunks):\n",
    "    embedding_model = watsonx_embedding()\n",
    "    vectordb = Chroma.from_documents(chunks, embedding_model)\n",
    "    return vectordb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
