{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df3bd26-5a22-4590-8d0c-88087ab1c2d9",
      "metadata": {
        "id": "0df3bd26-5a22-4590-8d0c-88087ab1c2d9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install ibm-watsonx-ai\n",
        "!pip install langchain-ibm\n",
        "!pip install langchain-community\n",
        "!pip install langchain\n",
        "!pip install gradio\n",
        "!pip install pypdf\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc68539-ffe8-4a3b-a3ac-a38003a9d857",
      "metadata": {
        "id": "ddc68539-ffe8-4a3b-a3ac-a38003a9d857"
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
        "from ibm_watsonx_ai import Credentials\n",
        "from langchain_ibm import WatsonxLLM, WatsonxEmbeddings\n",
        "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "import gradio as gr\n",
        "# You can use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde7b0f7-1e5e-4c6e-a4f4-9fcc354baa08",
      "metadata": {
        "id": "bde7b0f7-1e5e-4c6e-a4f4-9fcc354baa08"
      },
      "source": [
        "# Task 1: Load document using LangChain for different sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75efab30-6ecb-44a9-b435-dcdcf16ca35a",
      "metadata": {
        "id": "75efab30-6ecb-44a9-b435-dcdcf16ca35a"
      },
      "outputs": [],
      "source": [
        "def document_loader(file):\n",
        "    loader = PyPDFLoader(file)\n",
        "    pages = loader.load_and_split()\n",
        "    return pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe80c20-dc9e-4593-b1dd-2bf205620b72",
      "metadata": {
        "id": "1fe80c20-dc9e-4593-b1dd-2bf205620b72",
        "outputId": "1162679c-6035-4683-c0b8-7942359878e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A Comprehensive Review of Low-Rank\\nAdaptation in Large Language Models for\\nEfficient Parameter Tuning\\nSeptember 10, 2024\\nAbstract\\nNatural Language Processing (NLP) often involves pre-training large\\nmodels on extensive datasets and then adapting them for specific tasks\\nthrough fine-tuning. However, as these models grow larger, like GPT-3\\nwith 175 billion parameters, fully fine-tuning them becomes computa-\\ntionally expensive. We propose a novel method called LoRA (Low-Rank\\nAdaptation) that significantly reduces the overhead by freezing the orig-\\ninal model weights and only training small rank decomposition matrices.\\nThis leads to up to 10,000 times fewer trainable parameters and reduces\\nGPU memory usage by three times. LoRA not only maintains but some-\\ntimes surpasses fine-tuning performance on models like RoBERTa, De-\\nBERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\\nno extra latency during inference, making it more efficient for practical\\napplications. All relevant code an'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WgM1DaUn2SYPcCg_It57tA/A-Comprehensive-Review-of-Low-Rank-Adaptation-in-Large-Language-Models-for-Efficient-Parameter-Tuning-1.pdf'\n",
        "data = document_loader(pdf_url)\n",
        "text = \" \".join([page.page_content for page in data])\n",
        "first_1000_char = text[:1000]\n",
        "first_1000_char"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4b5b18-be9c-429a-ba73-26840f0ef7ff",
      "metadata": {
        "id": "7d4b5b18-be9c-429a-ba73-26840f0ef7ff"
      },
      "source": [
        "# Task 2: Apply text splitting techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8776aed4-eb8d-49ee-8dcd-e70ab3bc9b3b",
      "metadata": {
        "id": "8776aed4-eb8d-49ee-8dcd-e70ab3bc9b3b"
      },
      "outputs": [],
      "source": [
        "def text_splitter(data):\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "        language=Language.LATEX,\n",
        "        chunk_size=60,\n",
        "        chunk_overlap=5,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_text(data)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b906f01-db20-4f05-9c92-3ea9a586987c",
      "metadata": {
        "id": "9b906f01-db20-4f05-9c92-3ea9a586987c",
        "outputId": "b9529d0b-cd29-4f7b-e990-a414e3ed8000"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\\\documentclass{article}\\n\\n    \\x08egin{document}',\n",
              " '\\\\maketitle\\n\\n    \\\\section{Introduction}\\n\\n    Large',\n",
              " 'language models (LLMs) are a type of machine learning model',\n",
              " 'that can be trained on vast amounts of text data to',\n",
              " 'to generate human-like language. In recent years, LLMs have',\n",
              " 'have made significant advances in various natural language',\n",
              " 'processing tasks, including language translation, text',\n",
              " 'text generation, and sentiment analysis.',\n",
              " '\\\\subsection{History of LLMs}\\n\\nThe earliest LLMs were',\n",
              " 'were developed in the 1980s and 1990s, but they were',\n",
              " 'were limited by the amount of data that could be processed',\n",
              " 'and the computational power available at the time. In the',\n",
              " 'the past decade, however, advances in hardware and software',\n",
              " 'have made it possible to train LLMs on massive datasets,',\n",
              " 'leading to significant improvements in performance.',\n",
              " '\\\\subsection{Applications of LLMs}\\n\\nLLMs have many',\n",
              " 'many applications in the industry, including chatbots,',\n",
              " 'content creation, and virtual assistants. They can also be',\n",
              " 'be used in academia for research in linguistics,',\n",
              " 'psychology, and computational linguistics.\\n\\n\\\\end{document}']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "latex_text = \"\"\"\n",
        "\n",
        "    \\documentclass{article}\n",
        "\n",
        "    \\begin{document}\n",
        "\n",
        "    \\maketitle\n",
        "\n",
        "    \\section{Introduction}\n",
        "\n",
        "    Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
        "\n",
        "    \\subsection{History of LLMs}\n",
        "\n",
        "The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
        "\n",
        "\\subsection{Applications of LLMs}\n",
        "\n",
        "LLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
        "\n",
        "\\end{document}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "chunks = text_splitter(latex_text)\n",
        "chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742c1b67-ba66-405e-93c9-ccbbb98e76ae",
      "metadata": {
        "id": "742c1b67-ba66-405e-93c9-ccbbb98e76ae"
      },
      "source": [
        "# Task 3: Embed documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c33cc6b-7a15-41a2-8c56-b4ccfdb869ca",
      "metadata": {
        "id": "0c33cc6b-7a15-41a2-8c56-b4ccfdb869ca"
      },
      "outputs": [],
      "source": [
        "iam_token = \"your_iam_token_here\"  # Replace with the IAM token you just obtained\n",
        "\n",
        "def watsonx_embedding():\n",
        "    embed_params = {\n",
        "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
        "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
        "    }\n",
        "\n",
        "    # Initialize WatsonxEmbeddings with IAM token\n",
        "    watsonx_embedding = WatsonxEmbeddings(\n",
        "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
        "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "        project_id=\"skills-network\",\n",
        "        params=embed_params,\n",
        "    )\n",
        "\n",
        "    return watsonx_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233f1c16-4e6a-4c8c-aa6c-4570503e14ee",
      "metadata": {
        "id": "233f1c16-4e6a-4c8c-aa6c-4570503e14ee",
        "outputId": "c27268f4-ae4c-46bd-83de-8a25b7851bc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.06722455, -0.023730014, 0.017487874, -0.013195301, -0.03958462]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How are you?\"\n",
        "embed = watsonx_embedding()\n",
        "\n",
        "embedding_vec = embed.embed_documents([query])\n",
        "embedding_vec[0][:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f352b4a8-3d4a-4563-a03d-de48c648d9a7",
      "metadata": {
        "id": "f352b4a8-3d4a-4563-a03d-de48c648d9a7"
      },
      "source": [
        "# Task 4: Create and configure vector databases to store embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad85ed71-7999-4483-802a-2eb03157b7c2",
      "metadata": {
        "id": "ad85ed71-7999-4483-802a-2eb03157b7c2",
        "outputId": "ddfe4c48-e20f-4090-ffbc-9ca7540bd7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-01 12:24:01--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6363 (6.2K) [text/plain]\n",
            "Saving to: ‘new-Policies.txt’\n",
            "\n",
            "new-Policies.txt    100%[===================>]   6.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-01 12:24:01 (679 MB/s) - ‘new-Policies.txt’ saved [6363/6363]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587fb1b1-056e-4a5e-b71a-d51b52b4b04f",
      "metadata": {
        "id": "587fb1b1-056e-4a5e-b71a-d51b52b4b04f"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader('new-Policies.txt')\n",
        "text = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9264486-f1c1-455f-a5fc-b1cd28051009",
      "metadata": {
        "id": "b9264486-f1c1-455f-a5fc-b1cd28051009",
        "outputId": "fa917e88-b826-4106-caca-11993cd9571e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'new-Policies.txt'}, page_content='this policy. Regular reviews will ensure it remains relevant with changing technology and security'),\n",
              " Document(metadata={'source': 'new-Policies.txt'}, page_content='The policy is regularly reviewed to stay current with evolving technology and security best'),\n",
              " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical'),\n",
              " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical'),\n",
              " Document(metadata={'source': 'new-Policies.txt'}, page_content='This policy encourages the responsible use of mobile devices in line with legal and ethical')]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=10,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(text)\n",
        "\n",
        "embed_params = {\n",
        "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
        "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
        "}\n",
        "\n",
        "# Initialize WatsonxEmbeddings with IAM token\n",
        "watsonx_embedding = WatsonxEmbeddings(\n",
        "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    project_id=\"skills-network\",\n",
        "    params=embed_params,\n",
        ")\n",
        "vectordb = Chroma.from_documents(chunks, watsonx_embedding)\n",
        "query = \"Smoking policy\"\n",
        "search_result = vectordb.similarity_search(query, k=5)\n",
        "search_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c57ad354-e141-489d-9ee0-a8c429fed3e4",
      "metadata": {
        "id": "c57ad354-e141-489d-9ee0-a8c429fed3e4"
      },
      "source": [
        "# Task 5: Develop a retriever to fetch document segments based on queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753cfe76-55ef-45ca-b181-6d1d90adb980",
      "metadata": {
        "id": "753cfe76-55ef-45ca-b181-6d1d90adb980",
        "outputId": "3be6fe65-c8bc-4f20-d52d-42570ae9c578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'new-Policies.txt'}, page_content='and email use, including copyright and data protection laws.'),\n",
              " Document(metadata={'source': 'new-Policies.txt'}, page_content='and email use, including copyright and data protection laws.')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Email policy\"\n",
        "vectordb = Chroma.from_documents(chunks, watsonx_embedding)\n",
        "retriever = vectordb.as_retriever(search_kwargs={'k': 2})\n",
        "retriever.invoke(query)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}